{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import math\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "\n",
    "from lib import models, datasets\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.sparse.linalg as linalg\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import easydict as edict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "args = edict\n",
    "\n",
    "args.cache = '../checkpoint/train_features_labels_cache/colorization_embedding_128.t7'\n",
    "args.save_path = '../checkpoint/pseudos/colorization_nc_pseudo_wrn-28-2'\n",
    "os.makedirs(args.save_path, exist_ok=True)\n",
    "\n",
    "args.num_class = 10\n",
    "args.rng_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.int64\n",
      "torch.Size([50000, 128]) torch.Size([50000])\n"
     ]
    }
   ],
   "source": [
    "train_features = torch.load(args.cache)\n",
    "train_labels = torch.Tensor(datasets.CIFAR10Instance(root='../data', train=True).targets).long()\n",
    "\n",
    "print(train_features.dtype, train_labels.dtype)\n",
    "print(train_features.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use cpu because the follow computation need a lot of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "train_features, train_labels = train_features.to(device), train_labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36044, 49165, 37807,  ..., 42128, 15898, 31476])\n"
     ]
    }
   ],
   "source": [
    "num_train_data = train_labels.shape[0]\n",
    "num_class = torch.max(train_labels) + 1\n",
    "\n",
    "torch.manual_seed(args.rng_seed)\n",
    "torch.cuda.manual_seed_all(args.rng_seed)\n",
    "perm = torch.randperm(num_train_data).to(device)\n",
    "print(perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# constrained normalized cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity done\n",
      "L_sys done\n"
     ]
    }
   ],
   "source": [
    "K = 20\n",
    "def make_column_normalize(X):\n",
    "    return X.div(torch.norm(X, p=2, dim=0, keepdim=True))\n",
    "\n",
    "cosin_similarity = torch.mm(train_features, train_features.t())\n",
    "dist = (1 - cosin_similarity) / 2\n",
    "\n",
    "dist_sorted, idx = dist.topk(K, dim=1, largest=False, sorted=True)\n",
    "k_dist = dist_sorted[:, -1:]\n",
    "\n",
    "similarity_dense = torch.exp(-dist_sorted * 2 / k_dist)\n",
    "similarity_sparse = torch.zeros_like(cosin_similarity)\n",
    "similarity_sparse[torch.arange(num_train_data).view(-1, 1), idx[:, 1:]] = similarity_dense[:, 1:]\n",
    "similarity = torch.max(similarity_sparse, similarity_sparse.t())\n",
    "print('similarity done')\n",
    "\n",
    "degree = similarity.sum(0)\n",
    "degree_normed = (degree**(-0.5))\n",
    "L_sys = degree_normed.view(-1, 1) * (degree.diag() - similarity) * degree_normed.view(1, -1)\n",
    "print('L_sys done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvectors done\n",
      "tensor([0.0160, 0.0236, 0.0306, 0.0318, 0.0359, 0.0400, 0.0453, 0.0561, 0.0603,\n",
      "        0.0621, 0.0635, 0.0731, 0.0745, 0.0775, 0.0795, 0.0860, 0.0881, 0.0942,\n",
      "        0.0967, 0.1003, 0.1035, 0.1047, 0.1070, 0.1094, 0.1170, 0.1221, 0.1237,\n",
      "        0.1275, 0.1290, 0.1316, 0.1377, 0.1384, 0.1393, 0.1425, 0.1435, 0.1466,\n",
      "        0.1505, 0.1539, 0.1548, 0.1591, 0.1615, 0.1644, 0.1660, 0.1665, 0.1699,\n",
      "        0.1715, 0.1721, 0.1727, 0.1734, 0.1756, 0.1794, 0.1803, 0.1805, 0.1819,\n",
      "        0.1854, 0.1874, 0.1875, 0.1881, 0.1889, 0.1919, 0.1926, 0.1952, 0.1975,\n",
      "        0.1997, 0.2004, 0.2010, 0.2025, 0.2035, 0.2053, 0.2068, 0.2088, 0.2101,\n",
      "        0.2117, 0.2138, 0.2145, 0.2150, 0.2183, 0.2190, 0.2205, 0.2220, 0.2245,\n",
      "        0.2251, 0.2275, 0.2282, 0.2285, 0.2297, 0.2299, 0.2316, 0.2330, 0.2358,\n",
      "        0.2359, 0.2381, 0.2396, 0.2409, 0.2425, 0.2440, 0.2448, 0.2459, 0.2462,\n",
      "        0.2480, 0.2492, 0.2495, 0.2518, 0.2520, 0.2531, 0.2543, 0.2545, 0.2562,\n",
      "        0.2574, 0.2582, 0.2592, 0.2598, 0.2612, 0.2621, 0.2633, 0.2638, 0.2642,\n",
      "        0.2653, 0.2669, 0.2679, 0.2689, 0.2699, 0.2706, 0.2716, 0.2721, 0.2729,\n",
      "        0.2744, 0.2750, 0.2761, 0.2774, 0.2784, 0.2794, 0.2803, 0.2810, 0.2821,\n",
      "        0.2825, 0.2835, 0.2847, 0.2850, 0.2853, 0.2867, 0.2877, 0.2882, 0.2893,\n",
      "        0.2897, 0.2902, 0.2911, 0.2920, 0.2933, 0.2944, 0.2951, 0.2962, 0.2966,\n",
      "        0.2973, 0.2978, 0.2984, 0.2990, 0.2994, 0.3007, 0.3011, 0.3022, 0.3023,\n",
      "        0.3030, 0.3043, 0.3046, 0.3054, 0.3062, 0.3067, 0.3069, 0.3075, 0.3080,\n",
      "        0.3097, 0.3110, 0.3114, 0.3119, 0.3131, 0.3133, 0.3144, 0.3152, 0.3153,\n",
      "        0.3159, 0.3172, 0.3176, 0.3183, 0.3188, 0.3193, 0.3197, 0.3205, 0.3212,\n",
      "        0.3216, 0.3220, 0.3226, 0.3231, 0.3238, 0.3242, 0.3249, 0.3259, 0.3262,\n",
      "        0.3270])\n"
     ]
    }
   ],
   "source": [
    "num_eigenvectors = 200 # the number of precomputed spectral eigenvectors.\n",
    "\n",
    "eigenvalues, eigenvectors = linalg.eigs(L_sys.numpy(), k=num_eigenvectors, which='SR', tol=1e-2, maxiter=30000)\n",
    "eigenvalues, eigenvectors = torch.from_numpy(eigenvalues.real)[1:], torch.from_numpy(eigenvectors.real)[:, 1:]\n",
    "eigenvalues, idx = eigenvalues.sort()\n",
    "eigenvectors = eigenvectors[:, idx]\n",
    "print('eigenvectors done')\n",
    "print(eigenvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_labeled=  50 T_nc=1, prec=48.40, AUC=60.85\n",
      "num_labeled= 100 T_nc=1, prec=51.91, AUC=67.34\n",
      "num_labeled= 250 T_nc=1, prec=61.03, AUC=76.31\n",
      "num_labeled= 500 T_nc=1, prec=64.05, AUC=80.04\n",
      "num_labeled=1000 T_nc=1, prec=64.84, AUC=81.78\n",
      "num_labeled=2000 T_nc=1, prec=64.84, AUC=81.89\n",
      "num_labeled=4000 T_nc=1, prec=65.60, AUC=82.93\n",
      "num_labeled=8000 T_nc=1, prec=65.11, AUC=82.03\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(dpi=200)\n",
    "\n",
    "for num_labeled_data in [50, 100, 250, 500, 1000, 2000, 4000, 8000]:\n",
    "    # index of labeled and unlabeled\n",
    "    # even split\n",
    "    index_labeled = []\n",
    "    index_unlabeled = []\n",
    "    data_per_class = num_labeled_data // args.num_class\n",
    "    for c in range(10):\n",
    "        indexes_c = perm[train_labels[perm] == c]\n",
    "        index_labeled.append(indexes_c[:data_per_class])\n",
    "        index_unlabeled.append(indexes_c[data_per_class:])\n",
    "    index_labeled = torch.cat(index_labeled)\n",
    "    index_unlabeled = torch.cat(index_unlabeled)\n",
    "\n",
    "#     index_labeled = perm[:num_labeled_data]\n",
    "#     index_unlabeled = perm[num_labeled_data:]\n",
    "    \n",
    "    # prior\n",
    "    unary_prior = torch.zeros([num_train_data, num_class])\n",
    "    unary_prior[index_labeled, :] = -1\n",
    "    unary_prior[index_labeled, train_labels[index_labeled]] = 1\n",
    "    AQ = unary_prior.abs()\n",
    "    pd = degree.view(-1, 1) * (AQ + unary_prior) / 2\n",
    "    nd = degree.view(-1, 1) * (AQ - unary_prior) / 2\n",
    "    np_ratio = pd.sum(dim=0) / nd.sum(dim=0)\n",
    "    unary_prior_norm = (pd / np_ratio).sqrt() - (nd * np_ratio).sqrt()\n",
    "    unary_prior_norm = make_column_normalize(unary_prior_norm)\n",
    "    \n",
    "    # logits and prediction\n",
    "    alpha = 0\n",
    "    lambda_reverse = (1 / (eigenvalues - alpha)).view(1, -1)\n",
    "    logits = torch.mm(lambda_reverse * eigenvectors, torch.mm(eigenvectors.t(), unary_prior_norm))\n",
    "    logits = make_column_normalize(logits) * math.sqrt(logits.shape[0])   \n",
    "    logits = logits - logits.max(1, keepdim=True)[0]\n",
    "    _, predict = logits.max(dim=1)\n",
    "    \n",
    "    for temperature_nc in [1]:#, 2, 3, 5, 10, 15, 20, 25, 30, 35, 40, 100]:  \n",
    "        # pseudo weights\n",
    "        logits_sorted = logits.sort(dim=1, descending=True)[0]\n",
    "        subtract = logits_sorted[:, 0] - logits_sorted[:, 1]\n",
    "        pseudo_weights = 1 - torch.exp(- subtract / temperature_nc)\n",
    "        \n",
    "        exp = (logits * temperature_nc).exp()\n",
    "        probs = exp / exp.sum(1, keepdim=True)\n",
    "        probs_sorted, predict_all = probs.sort(1, True)\n",
    "        assert torch.all(predict == predict_all[:, 0])\n",
    "\n",
    "        idx = pseudo_weights[index_unlabeled].sort(dim=0, descending=True)[1]\n",
    "        pseudo_indexes = index_unlabeled[idx]\n",
    "        pseudo_labels = predict[index_unlabeled][idx]\n",
    "        pseudo_probs = probs[index_unlabeled][idx]\n",
    "        pseudo_weights = pseudo_weights[index_unlabeled][idx]\n",
    "        assert torch.all(pseudo_labels == pseudo_probs.max(1)[1])\n",
    "        \n",
    "        save_dict = {\n",
    "            'pseudo_indexes': pseudo_indexes,\n",
    "            'pseudo_labels': pseudo_labels,\n",
    "            'pseudo_probs': pseudo_probs,\n",
    "            'pseudo_weights': pseudo_weights,\n",
    "            'labeled_indexes': index_labeled,\n",
    "            'unlabeled_indexes': index_unlabeled,\n",
    "        }\n",
    "        torch.save(save_dict, os.path.join(args.save_path, '{}.pth.tar'.format(num_labeled_data)))\n",
    "\n",
    "        # for plot\n",
    "        correct = pseudo_labels == train_labels[pseudo_indexes]\n",
    "        \n",
    "        entropy = - (pseudo_probs * torch.log(pseudo_probs + 1e-7)).sum(dim=1)\n",
    "        confidence = (- entropy * 1).exp()\n",
    "        confidence /= confidence.max()\n",
    "\n",
    "        arange = 1 + np.arange(confidence.shape[0])\n",
    "        xs = arange / confidence.shape[0]\n",
    "        correct_tmp = correct[confidence.sort(descending=True)[1]]\n",
    "        accuracies = np.cumsum(correct_tmp.numpy()) / arange\n",
    "        plt.plot(xs, accuracies, label='num_labeled_data={}'.format(num_labeled_data))\n",
    "\n",
    "        acc = correct.float().mean()\n",
    "\n",
    "        print('num_labeled={:4} T_nc={}, prec={:.2f}, AUC={:.2f}'.format(\n",
    "            num_labeled_data, temperature_nc, acc * 100, accuracies.mean() * 100))\n",
    "    \n",
    "plt.xlabel('accumulated unlabeled data ratio')\n",
    "plt.ylabel('unlabeled top1 accuracy')\n",
    "plt.xticks(np.arange(0, 1.01, 0.1))\n",
    "plt.grid()\n",
    "plt.title('num_eigenvectors={}'.format(num_eigenvectors))\n",
    "legend = plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
