{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import easydict as edict\n",
    "\n",
    "from lib import models, datasets\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "args = edict\n",
    "\n",
    "# imagenet\n",
    "args.cache = '../checkpoint/train_features_labels_cache/instance_imagenet_train_feature_resnet50.pth.tar'\n",
    "args.val_cache = '../checkpoint/train_features_labels_cache/instance_imagenet_val_feature_resnet50.pth.tar'\n",
    "args.save_path = '../checkpoint/pseudos/unsupervised_imagenet32x32_nc_wrn-28-2'\n",
    "os.makedirs(args.save_path, exist_ok=True)\n",
    "\n",
    "args.low_dim = 128\n",
    "args.num_class = 1000\n",
    "args.rng_seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.int64\n",
      "torch.Size([1331167, 128]) torch.Size([1331167])\n"
     ]
    }
   ],
   "source": [
    "ckpt = torch.load(args.cache)\n",
    "train_labels, train_features = ckpt['labels'], ckpt['features']\n",
    "\n",
    "ckpt = torch.load(args.val_cache)\n",
    "val_labels, val_features = ckpt['val_labels'], ckpt['val_features']\n",
    "\n",
    "train_features = torch.cat([val_features, train_features], dim=0)\n",
    "train_labels = torch.cat([val_labels, train_labels], dim=0)\n",
    "\n",
    "print(train_features.dtype, train_labels.dtype)\n",
    "print(train_features.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use cpu because the following computation need a lot of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "train_features, train_labels = train_features.to(device), train_labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 970454, 1058848,  717280,  ...,  462299,  305137,  436069])\n"
     ]
    }
   ],
   "source": [
    "num_train_data = train_labels.shape[0]\n",
    "num_class = torch.max(train_labels) + 1\n",
    "\n",
    "torch.manual_seed(args.rng_seed)\n",
    "torch.cuda.manual_seed_all(args.rng_seed)\n",
    "perm = torch.randperm(num_train_data).to(device)\n",
    "print(perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# soft label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]/[100] top5=85.00%(85.00%) top1=66.60%(66.60%)\n",
      "[1]/[100] top5=79.60%(82.30%) top1=52.80%(59.70%)\n",
      "[2]/[100] top5=81.00%(81.87%) top1=61.40%(60.27%)\n",
      "[3]/[100] top5=65.20%(77.70%) top1=42.80%(55.90%)\n",
      "[4]/[100] top5=70.00%(76.16%) top1=47.40%(54.20%)\n",
      "[5]/[100] top5=69.20%(75.00%) top1=42.60%(52.27%)\n",
      "[6]/[100] top5=67.20%(73.89%) top1=41.40%(50.71%)\n",
      "[7]/[100] top5=77.60%(74.35%) top1=52.20%(50.90%)\n",
      "[8]/[100] top5=84.60%(75.49%) top1=67.00%(52.69%)\n",
      "[9]/[100] top5=77.40%(75.68%) top1=57.00%(53.12%)\n",
      "[10]/[100] top5=82.20%(76.27%) top1=67.00%(54.38%)\n",
      "[11]/[100] top5=71.00%(75.83%) top1=49.00%(53.93%)\n",
      "[12]/[100] top5=65.20%(75.02%) top1=43.80%(53.15%)\n",
      "[13]/[100] top5=83.00%(75.59%) top1=62.20%(53.80%)\n",
      "[14]/[100] top5=85.20%(76.23%) top1=66.80%(54.67%)\n",
      "[15]/[100] top5=71.80%(75.95%) top1=43.60%(53.97%)\n",
      "[16]/[100] top5=62.20%(75.14%) top1=39.80%(53.14%)\n",
      "[17]/[100] top5=61.00%(74.36%) top1=38.80%(52.34%)\n",
      "[18]/[100] top5=63.60%(73.79%) top1=36.60%(51.52%)\n",
      "[19]/[100] top5=67.40%(73.47%) top1=41.60%(51.02%)\n",
      "[20]/[100] top5=70.40%(73.32%) top1=38.40%(50.42%)\n",
      "[21]/[100] top5=71.40%(73.24%) top1=46.60%(50.25%)\n",
      "[22]/[100] top5=71.00%(73.14%) top1=48.40%(50.17%)\n",
      "[23]/[100] top5=76.20%(73.27%) top1=44.00%(49.91%)\n",
      "[24]/[100] top5=71.20%(73.18%) top1=41.60%(49.58%)\n",
      "[25]/[100] top5=78.60%(73.39%) top1=55.40%(49.80%)\n",
      "[26]/[100] top5=67.20%(73.16%) top1=45.00%(49.62%)\n",
      "[27]/[100] top5=74.80%(73.22%) top1=52.60%(49.73%)\n",
      "[28]/[100] top5=74.80%(73.28%) top1=47.00%(49.63%)\n",
      "[29]/[100] top5=79.40%(73.48%) top1=57.80%(49.91%)\n",
      "[30]/[100] top5=78.20%(73.63%) top1=51.00%(49.94%)\n",
      "[31]/[100] top5=64.20%(73.34%) top1=37.20%(49.54%)\n",
      "[32]/[100] top5=86.00%(73.72%) top1=71.40%(50.21%)\n",
      "[33]/[100] top5=83.00%(73.99%) top1=61.00%(50.52%)\n",
      "[34]/[100] top5=75.80%(74.05%) top1=52.00%(50.57%)\n",
      "[35]/[100] top5=71.00%(73.96%) top1=44.00%(50.38%)\n",
      "[36]/[100] top5=73.80%(73.96%) top1=53.40%(50.46%)\n",
      "[37]/[100] top5=73.80%(73.95%) top1=51.80%(50.50%)\n",
      "[38]/[100] top5=78.80%(74.08%) top1=47.80%(50.43%)\n",
      "[39]/[100] top5=75.80%(74.12%) top1=57.40%(50.60%)\n",
      "[40]/[100] top5=76.20%(74.17%) top1=54.20%(50.69%)\n",
      "[41]/[100] top5=62.20%(73.89%) top1=35.80%(50.34%)\n",
      "[42]/[100] top5=67.80%(73.74%) top1=49.00%(50.31%)\n",
      "[43]/[100] top5=66.00%(73.57%) top1=45.40%(50.20%)\n",
      "[44]/[100] top5=67.60%(73.44%) top1=43.40%(50.04%)\n",
      "[45]/[100] top5=66.60%(73.29%) top1=44.20%(49.92%)\n",
      "[46]/[100] top5=58.80%(72.98%) top1=34.20%(49.58%)\n",
      "[47]/[100] top5=65.60%(72.83%) top1=48.60%(49.56%)\n",
      "[48]/[100] top5=67.60%(72.72%) top1=40.20%(49.37%)\n",
      "[49]/[100] top5=56.60%(72.40%) top1=36.60%(49.12%)\n",
      "[50]/[100] top5=59.20%(72.14%) top1=37.40%(48.89%)\n",
      "[51]/[100] top5=64.00%(71.98%) top1=38.20%(48.68%)\n",
      "[52]/[100] top5=68.60%(71.92%) top1=43.80%(48.59%)\n",
      "[53]/[100] top5=68.40%(71.85%) top1=51.80%(48.65%)\n",
      "[54]/[100] top5=67.20%(71.77%) top1=50.40%(48.68%)\n",
      "[55]/[100] top5=64.80%(71.64%) top1=45.20%(48.62%)\n",
      "[56]/[100] top5=78.40%(71.76%) top1=63.80%(48.88%)\n"
     ]
    }
   ],
   "source": [
    "n_chunks = 100\n",
    "n_val = val_features.shape[0]\n",
    "\n",
    "prec_top5 = AverageMeter()\n",
    "prec_top1 = AverageMeter()\n",
    "index_labeled = torch.arange(n_val, train_features.shape[0])\n",
    "index_unlabeled = torch.arange(n_val)\n",
    "num_labeled_data = index_labeled.shape[0]\n",
    "\n",
    "for i_chunks, index_unlabeled_chunk in enumerate(index_unlabeled.chunk(n_chunks)):\n",
    "\n",
    "    # calculate similarity matrix\n",
    "    dist = torch.mm(train_features[index_unlabeled_chunk], train_features[index_labeled].t())\n",
    "\n",
    "    K = min(num_labeled_data, 200)\n",
    "    bs = index_unlabeled_chunk.shape[0]\n",
    "    yd, yi = dist.topk(K, dim=1, largest=True, sorted=True)\n",
    "    candidates = train_labels.view(1,-1).expand(bs, -1)\n",
    "    retrieval = torch.gather(candidates, 1, index_labeled[yi])\n",
    "    retrieval_one_hot = torch.zeros(bs * K, num_class).to(device)\n",
    "    retrieval_one_hot.scatter_(1, retrieval.view(-1, 1), 1)\n",
    "\n",
    "    temperature = 0.1\n",
    "\n",
    "    yd_transform = (yd / temperature).exp_()\n",
    "    probs = torch.sum(torch.mul(retrieval_one_hot.view(bs, -1 , num_class), yd_transform.view(bs, -1, 1)), 1)\n",
    "    probs.div_(probs.sum(dim=1, keepdim=True))\n",
    "    probs_sorted, predictions = probs.sort(1, True)\n",
    "    correct = predictions.eq(train_labels[index_unlabeled_chunk].data.view(-1,1))\n",
    "    \n",
    "    top5 = torch.any(correct[:, :5], dim=1).float().mean() \n",
    "    top1 = correct[:, 0].float().mean() \n",
    "    prec_top5.update(top5, bs)\n",
    "    prec_top1.update(top1, bs)\n",
    "    print('[{}]/[{}] top5={:.2%}({:.2%}) top1={:.2%}({:.2%})'.format(\n",
    "        i_chunks, n_chunks, prec_top5.val, prec_top5.avg, prec_top1.val, prec_top1.avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# n_chunks = 100\n",
    "\n",
    "# prec_top5 = AverageMeter()\n",
    "# for num_labeled_data in [10000]:\n",
    "#     index_labeled = []\n",
    "#     index_unlabeled = []\n",
    "#     data_per_class = num_labeled_data // args.num_class\n",
    "#     for c in range(args.num_class):\n",
    "#         indexes_c = perm[train_labels[perm] == c]\n",
    "#         index_labeled.append(indexes_c[:data_per_class])\n",
    "#         index_unlabeled.append(indexes_c[data_per_class:])\n",
    "#     index_labeled = torch.cat(index_labeled)\n",
    "#     index_unlabeled = torch.cat(index_unlabeled)\n",
    "\n",
    "#     for i_chunks, index_unlabeled_chunk in enumerate(index_unlabeled.chunk(n_chunks)):\n",
    "    \n",
    "#         # calculate similarity matrix\n",
    "#         dist = torch.mm(train_features[index_unlabeled_chunk], train_features[index_labeled].t())\n",
    "\n",
    "#         K = min(num_labeled_data, 5000)\n",
    "#         bs = index_unlabeled_chunk.shape[0]\n",
    "#         yd, yi = dist.topk(K, dim=1, largest=True, sorted=True)\n",
    "#         candidates = train_labels.view(1,-1).expand(bs, -1)\n",
    "#         retrieval = torch.gather(candidates, 1, index_labeled[yi])\n",
    "#         retrieval_one_hot = torch.zeros(bs * K, num_class).to(device)\n",
    "#         retrieval_one_hot.scatter_(1, retrieval.view(-1, 1), 1)\n",
    "\n",
    "#         temperature = 0.1\n",
    "\n",
    "#         yd_transform = (yd / temperature).exp_()\n",
    "#         probs = torch.sum(torch.mul(retrieval_one_hot.view(bs, -1 , num_class), yd_transform.view(bs, -1, 1)), 1)\n",
    "#         probs.div_(probs.sum(dim=1, keepdim=True))\n",
    "#         probs_sorted, predictions = probs.sort(1, True)\n",
    "#         correct = predictions.eq(train_labels[index_unlabeled_chunk].data.view(-1,1))\n",
    "#         top5 = torch.any(correct[:, :5], dim=1).float().mean() \n",
    "        \n",
    "#         prec_top5.update(top5, bs)\n",
    "#         print('[{}]/[{}] {:.2%} {:.2%}'.format(i_chunks, n_chunks, prec_top5.val, prec_top5.avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
